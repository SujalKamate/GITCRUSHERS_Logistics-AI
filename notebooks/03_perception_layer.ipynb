{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Perception Layer\n",
    "\n",
    "## Agentic Logistics Control System\n",
    "\n",
    "This notebook implements the perception/observation layer:\n",
    "- GPS data collection from trucks\n",
    "- Traffic condition monitoring\n",
    "- Load manifest collection\n",
    "- Data preprocessing and validation\n",
    "- LangGraph observation node\n",
    "\n",
    "### Control Loop Role: OBSERVATION\n",
    "\n",
    "```\n",
    "[OBSERVE] -> REASON -> PLAN -> DECIDE -> ACT -> FEEDBACK -> (loop)\n",
    "    ^\n",
    "    |\n",
    "  YOU ARE HERE\n",
    "```\n",
    "\n",
    "The observation phase gathers all data needed for the reasoning layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "# For Jupyter async compatibility\n",
    "import nest_asyncio\n",
    "try:\n",
    "    nest_asyncio.apply()\n",
    "except:\n",
    "    pass  # May not be needed in all environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "from src.models import (\n",
    "    Truck, TruckStatus, Location, GPSReading,\n",
    "    TrafficCondition, TrafficLevel, Load, LoadPriority,\n",
    "    Route, AgentState, ControlLoopPhase\n",
    ")\n",
    "from src.perception.collectors import (\n",
    "    GPSCollector, TrafficCollector, LoadCollector, AggregatedCollector\n",
    ")\n",
    "from src.perception.preprocessor import DataPreprocessor\n",
    "from src.perception.observation_node import create_observation_node, create_sample_fleet\n",
    "\n",
    "print(\"Perception layer modules loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPS Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample fleet\n",
    "fleet = create_sample_fleet()\n",
    "\n",
    "print(f\"Fleet size: {len(fleet)} trucks\")\n",
    "for truck in fleet:\n",
    "    print(f\"  {truck.id}: {truck.name} - {truck.status.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GPS collector\n",
    "gps_collector = GPSCollector(trucks=fleet, simulate=True)\n",
    "\n",
    "# Collect GPS readings\n",
    "async def collect_gps():\n",
    "    return await gps_collector.collect()\n",
    "\n",
    "gps_readings = asyncio.get_event_loop().run_until_complete(collect_gps())\n",
    "\n",
    "print(f\"\\nCollected {len(gps_readings)} GPS readings:\")\n",
    "for reading in gps_readings:\n",
    "    print(f\"  {reading.truck_id}: ({reading.location.latitude:.4f}, {reading.location.longitude:.4f}) @ {reading.speed_kmh:.1f} km/h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect multiple times to see movement simulation\n",
    "print(\"Simulating truck movement over 3 collection cycles:\\n\")\n",
    "\n",
    "for cycle in range(3):\n",
    "    readings = asyncio.get_event_loop().run_until_complete(collect_gps())\n",
    "    print(f\"Cycle {cycle + 1}:\")\n",
    "    for r in readings[:3]:  # Show first 3\n",
    "        print(f\"  {r.truck_id}: {r.speed_kmh:.1f} km/h, heading {r.heading:.0f}°\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Traffic Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traffic collector\n",
    "traffic_collector = TrafficCollector(simulate=True)\n",
    "\n",
    "# Collect traffic conditions\n",
    "async def collect_traffic():\n",
    "    return await traffic_collector.collect()\n",
    "\n",
    "traffic_conditions = asyncio.get_event_loop().run_until_complete(collect_traffic())\n",
    "\n",
    "print(f\"Collected {len(traffic_conditions)} traffic conditions:\\n\")\n",
    "for tc in traffic_conditions:\n",
    "    incident = f\" - {tc.incident_description}\" if tc.incident_description else \"\"\n",
    "    print(f\"  {tc.segment_id}: {tc.level.value} ({tc.speed_kmh:.0f} km/h){incident}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for traffic incidents\n",
    "incidents = [tc for tc in traffic_conditions if tc.incident_description]\n",
    "heavy_traffic = [tc for tc in traffic_conditions if tc.level in [TrafficLevel.HEAVY, TrafficLevel.STANDSTILL]]\n",
    "\n",
    "print(f\"Traffic Summary:\")\n",
    "print(f\"  Incidents: {len(incidents)}\")\n",
    "print(f\"  Heavy/Standstill: {len(heavy_traffic)}\")\n",
    "\n",
    "if incidents:\n",
    "    print(f\"\\nIncident Details:\")\n",
    "    for tc in incidents:\n",
    "        print(f\"  {tc.segment_id}: {tc.incident_description}\")\n",
    "        print(f\"    Delay: {tc.delay_minutes:.0f} min, Speed: {tc.speed_kmh:.0f} km/h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create load collector\n",
    "load_collector = LoadCollector(simulate=True)\n",
    "\n",
    "# Collect loads\n",
    "async def collect_loads():\n",
    "    return await load_collector.collect()\n",
    "\n",
    "loads = asyncio.get_event_loop().run_until_complete(collect_loads())\n",
    "\n",
    "print(f\"Collected {len(loads)} loads:\\n\")\n",
    "for load in loads:\n",
    "    hours_to_deadline = (load.delivery_deadline - datetime.utcnow()).total_seconds() / 3600 if load.delivery_deadline else 0\n",
    "    print(f\"  {load.id}: {load.description[:30]}...\")\n",
    "    print(f\"    Priority: {load.priority.value}, Weight: {load.weight_kg:.0f} kg\")\n",
    "    print(f\"    Deadline: {hours_to_deadline:.1f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aggregated Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all data concurrently\n",
    "aggregator = AggregatedCollector(\n",
    "    gps_collector=GPSCollector(trucks=fleet, simulate=True),\n",
    "    traffic_collector=TrafficCollector(simulate=True),\n",
    "    load_collector=LoadCollector(simulate=True)\n",
    ")\n",
    "\n",
    "async def collect_all():\n",
    "    return await aggregator.collect_all()\n",
    "\n",
    "all_data = asyncio.get_event_loop().run_until_complete(collect_all())\n",
    "\n",
    "print(\"Aggregated Collection Results:\")\n",
    "print(f\"  Timestamp: {all_data['timestamp']}\")\n",
    "print(f\"  GPS Readings: {all_data['collection_stats']['gps_count']}\")\n",
    "print(f\"  Traffic Segments: {all_data['collection_stats']['traffic_segments']}\")\n",
    "print(f\"  Active Loads: {all_data['collection_stats']['active_loads']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Preprocess GPS readings\n",
    "validated_gps, updated_trucks = preprocessor.preprocess_gps_readings(\n",
    "    all_data['gps_readings'],\n",
    "    fleet\n",
    ")\n",
    "\n",
    "print(f\"GPS Preprocessing:\")\n",
    "print(f\"  Input: {len(all_data['gps_readings'])} readings\")\n",
    "print(f\"  Output: {len(validated_gps)} validated readings\")\n",
    "print(f\"  Validation errors: {len(preprocessor.validation_errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess traffic conditions\n",
    "routes = []  # Empty routes for now\n",
    "validated_traffic = preprocessor.preprocess_traffic_conditions(\n",
    "    all_data['traffic_conditions'],\n",
    "    routes\n",
    ")\n",
    "\n",
    "print(f\"Traffic Preprocessing:\")\n",
    "print(f\"  Input: {len(all_data['traffic_conditions'])} conditions\")\n",
    "print(f\"  Output: {len(validated_traffic)} validated conditions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess loads\n",
    "validated_loads = preprocessor.preprocess_loads(all_data['loads'])\n",
    "\n",
    "print(f\"Load Preprocessing:\")\n",
    "print(f\"  Input: {len(all_data['loads'])} loads\")\n",
    "print(f\"  Output: {len(validated_loads)} validated loads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check preprocessing summary\n",
    "summary = preprocessor.get_preprocessing_summary()\n",
    "\n",
    "print(\"Preprocessing Summary:\")\n",
    "print(f\"  Timestamp: {summary['timestamp']}\")\n",
    "print(f\"  Validation Errors: {summary['validation_errors']}\")\n",
    "print(f\"  Anomalies Detected: {summary['anomalies_detected']}\")\n",
    "\n",
    "if summary['recent_anomalies']:\n",
    "    print(\"\\nRecent Anomalies:\")\n",
    "    for anomaly in summary['recent_anomalies']:\n",
    "        print(f\"  [{anomaly['type']}] {anomaly.get('details', 'No details')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LangGraph Observation Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the observation node\n",
    "observation_node = create_observation_node()\n",
    "\n",
    "# Create initial state\n",
    "initial_state: AgentState = {\n",
    "    \"current_phase\": ControlLoopPhase.OBSERVE,\n",
    "    \"cycle_id\": str(uuid.uuid4()),\n",
    "    \"trucks\": [t.model_dump() for t in fleet],\n",
    "    \"routes\": [],\n",
    "    \"loads\": [],\n",
    "    \"traffic_conditions\": [],\n",
    "    \"gps_readings\": [],\n",
    "    \"observation_timestamp\": \"\",\n",
    "    \"reasoning_result\": None,\n",
    "    \"current_issues\": [],\n",
    "    \"planning_result\": None,\n",
    "    \"scenarios\": [],\n",
    "    \"decision_result\": None,\n",
    "    \"selected_decision\": None,\n",
    "    \"action_results\": [],\n",
    "    \"notifications_sent\": [],\n",
    "    \"feedback_result\": None,\n",
    "    \"continue_loop\": True,\n",
    "    \"requires_human_intervention\": False,\n",
    "    \"error_message\": None,\n",
    "    \"cycle_start_time\": datetime.utcnow().isoformat(),\n",
    "    \"cycle_end_time\": None,\n",
    "    \"total_cycles\": 0,\n",
    "}\n",
    "\n",
    "print(f\"Initial state created for cycle: {initial_state['cycle_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run observation node\n",
    "observed_state = observation_node(initial_state)\n",
    "\n",
    "print(\"Observation Node Results:\")\n",
    "print(f\"  Phase: {observed_state['current_phase']}\")\n",
    "print(f\"  Timestamp: {observed_state['observation_timestamp']}\")\n",
    "print(f\"  Trucks: {len(observed_state['trucks'])}\")\n",
    "print(f\"  GPS Readings: {len(observed_state['gps_readings'])}\")\n",
    "print(f\"  Traffic Conditions: {len(observed_state['traffic_conditions'])}\")\n",
    "print(f\"  Loads: {len(observed_state['loads'])}\")\n",
    "print(f\"  Continue Loop: {observed_state['continue_loop']}\")\n",
    "print(f\"  Error: {observed_state['error_message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Workflow Scenarios\n",
    "\n",
    "### Scenario A: Normal Observation Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal observation cycle\n",
    "print(\"=\" * 50)\n",
    "print(\"SCENARIO A: Normal Observation Cycle\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "state_a = observation_node(initial_state)\n",
    "\n",
    "# Check for issues\n",
    "stuck_trucks = [t for t in state_a['trucks'] if t['status'] == 'stuck']\n",
    "heavy_traffic = [tc for tc in state_a['traffic_conditions'] \n",
    "                 if tc['level'] in ['heavy', 'standstill']]\n",
    "urgent_loads = [l for l in state_a['loads'] \n",
    "                if l['priority'] in ['urgent', 'critical']]\n",
    "\n",
    "print(f\"\\nFleet Status:\")\n",
    "print(f\"  Active trucks: {len(state_a['trucks'])}\")\n",
    "print(f\"  Stuck trucks: {len(stuck_trucks)}\")\n",
    "\n",
    "print(f\"\\nTraffic Status:\")\n",
    "print(f\"  Segments monitored: {len(state_a['traffic_conditions'])}\")\n",
    "print(f\"  Heavy/Standstill: {len(heavy_traffic)}\")\n",
    "\n",
    "print(f\"\\nLoad Status:\")\n",
    "print(f\"  Active loads: {len(state_a['loads'])}\")\n",
    "print(f\"  Urgent/Critical: {len(urgent_loads)}\")\n",
    "\n",
    "print(f\"\\nReady for reasoning phase: {state_a['continue_loop']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario B: Missing Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data scenario - empty fleet\n",
    "print(\"=\" * 50)\n",
    "print(\"SCENARIO B: Missing Data Handling\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "empty_state: AgentState = {\n",
    "    **initial_state,\n",
    "    \"cycle_id\": str(uuid.uuid4()),\n",
    "    \"trucks\": [],  # No trucks\n",
    "}\n",
    "\n",
    "state_b = observation_node(empty_state)\n",
    "\n",
    "print(f\"\\nResults with no trucks:\")\n",
    "print(f\"  GPS Readings: {len(state_b['gps_readings'])}\")\n",
    "print(f\"  Traffic still collected: {len(state_b['traffic_conditions'])}\")\n",
    "print(f\"  Loads still collected: {len(state_b['loads'])}\")\n",
    "print(f\"  Continue Loop: {state_b['continue_loop']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario C: High-Frequency Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-frequency collection simulation\n",
    "print(\"=\" * 50)\n",
    "print(\"SCENARIO C: High-Frequency Batch Processing\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import time\n",
    "\n",
    "num_cycles = 5\n",
    "cycle_times = []\n",
    "current_state = initial_state.copy()\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    start = time.time()\n",
    "    \n",
    "    current_state = observation_node({\n",
    "        **current_state,\n",
    "        \"cycle_id\": str(uuid.uuid4()),\n",
    "        \"total_cycles\": i + 1,\n",
    "    })\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    cycle_times.append(elapsed)\n",
    "    \n",
    "    print(f\"Cycle {i+1}: {elapsed*1000:.1f}ms, {len(current_state['gps_readings'])} GPS readings\")\n",
    "\n",
    "avg_time = sum(cycle_times) / len(cycle_times)\n",
    "print(f\"\\nAverage cycle time: {avg_time*1000:.1f}ms\")\n",
    "print(f\"Max throughput: ~{1/avg_time:.0f} cycles/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Integration Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full integration test\n",
    "print(\"=\" * 50)\n",
    "print(\"PERCEPTION LAYER INTEGRATION TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tests_passed = 0\n",
    "tests_total = 0\n",
    "\n",
    "# Test 1: Observation node creation\n",
    "tests_total += 1\n",
    "try:\n",
    "    test_node = create_observation_node()\n",
    "    assert callable(test_node)\n",
    "    print(\"✓ Test 1: Observation node creation\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 1: {e}\")\n",
    "\n",
    "# Test 2: GPS collection\n",
    "tests_total += 1\n",
    "try:\n",
    "    collector = GPSCollector(trucks=fleet, simulate=True)\n",
    "    readings = asyncio.get_event_loop().run_until_complete(collector.collect())\n",
    "    assert len(readings) == len(fleet)\n",
    "    print(\"✓ Test 2: GPS collection\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 2: {e}\")\n",
    "\n",
    "# Test 3: Traffic collection\n",
    "tests_total += 1\n",
    "try:\n",
    "    collector = TrafficCollector(simulate=True)\n",
    "    conditions = asyncio.get_event_loop().run_until_complete(collector.collect())\n",
    "    assert len(conditions) > 0\n",
    "    print(\"✓ Test 3: Traffic collection\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 3: {e}\")\n",
    "\n",
    "# Test 4: Load collection\n",
    "tests_total += 1\n",
    "try:\n",
    "    collector = LoadCollector(simulate=True)\n",
    "    loads = asyncio.get_event_loop().run_until_complete(collector.collect())\n",
    "    assert len(loads) > 0\n",
    "    print(\"✓ Test 4: Load collection\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 4: {e}\")\n",
    "\n",
    "# Test 5: Preprocessor\n",
    "tests_total += 1\n",
    "try:\n",
    "    preprocessor = DataPreprocessor()\n",
    "    summary = preprocessor.get_preprocessing_summary()\n",
    "    assert 'timestamp' in summary\n",
    "    print(\"✓ Test 5: Preprocessor\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 5: {e}\")\n",
    "\n",
    "# Test 6: Full observation cycle\n",
    "tests_total += 1\n",
    "try:\n",
    "    result = observation_node(initial_state)\n",
    "    assert result['observation_timestamp'] != \"\"\n",
    "    assert result['continue_loop'] == True\n",
    "    print(\"✓ Test 6: Full observation cycle\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 6: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tests passed: {tests_passed}/{tests_total}\")\n",
    "if tests_passed == tests_total:\n",
    "    print(\"✓ All tests passed! Perception layer ready.\")\n",
    "else:\n",
    "    print(\"✗ Some tests failed. Please review.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. The observation phase is complete\n",
    "2. Proceed to `04_grok_integration.ipynb` for Grok LLM setup\n",
    "3. Then `05_reasoning_prompts.ipynb` and `06_reasoning_layer.ipynb` for the REASON phase\n",
    "\n",
    "### State Transition\n",
    "\n",
    "The observed state is now ready to be passed to the reasoning layer:\n",
    "```python\n",
    "# After observation\n",
    "state = observation_node(initial_state)\n",
    "\n",
    "# Pass to reasoning (next phase)\n",
    "state = reasoning_node(state)  # Implemented in Phase 2\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
