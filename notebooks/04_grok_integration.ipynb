{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Grok Integration\n",
    "\n",
    "## Agentic Logistics Control System\n",
    "\n",
    "This notebook implements integration with xAI's Grok LLM:\n",
    "- API client setup and configuration\n",
    "- Rate limiting and retry logic\n",
    "- Error handling and fallbacks\n",
    "- Response parsing and validation\n",
    "\n",
    "### Control Loop Role: Foundation for REASONING\n",
    "\n",
    "```\n",
    "OBSERVE -> [REASON] -> PLAN -> DECIDE -> ACT -> FEEDBACK -> (loop)\n",
    "            ^\n",
    "            |\n",
    "      Grok powers this\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config.settings import settings\n",
    "\n",
    "print(\"Current configuration:\")\n",
    "print(f\"  API Base URL: {settings.XAI_BASE_URL}\")\n",
    "print(f\"  Model: {settings.GROK_MODEL}\")\n",
    "print(f\"  Temperature: {settings.LLM_TEMPERATURE}\")\n",
    "print(f\"  Max Tokens: {settings.LLM_MAX_TOKENS}\")\n",
    "print(f\"  API Key configured: {bool(settings.XAI_API_KEY)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grok Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.reasoning.grok_client import GrokClient, get_grok_client\n",
    "\n",
    "# Create client\n",
    "client = GrokClient()\n",
    "\n",
    "print(f\"Client Status:\")\n",
    "print(f\"  Is Available: {client.is_available}\")\n",
    "print(f\"  Model: {client.model}\")\n",
    "print(f\"  Temperature: {client.temperature}\")\n",
    "print(f\"  Max Tokens: {client.max_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic completion (will use fallback if API key not configured)\n",
    "response = client.complete(\n",
    "    prompt=\"What are the top 3 factors to consider when optimizing truck routes?\",\n",
    "    system_prompt=\"You are a logistics expert. Be concise.\"\n",
    ")\n",
    "\n",
    "print(f\"Response:\")\n",
    "print(f\"  Success: {response['success']}\")\n",
    "print(f\"  Model: {response['model']}\")\n",
    "print(f\"  Finish Reason: {response['finish_reason']}\")\n",
    "print(f\"\\nContent:\\n{response['content'][:500]}...\" if len(response['content']) > 500 else f\"\\nContent:\\n{response['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. JSON Mode Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test JSON completion\n",
    "json_response = client.complete_json(\n",
    "    prompt=\"\"\"Analyze this truck status:\n",
    "    - Truck ID: TRK-001\n",
    "    - Speed: 5 km/h for last 15 minutes\n",
    "    - Expected speed: 60 km/h\n",
    "    - Traffic: Heavy on current segment\n",
    "    \n",
    "    Return a JSON object with: is_stuck (bool), severity (low/medium/high), recommendation (string)\"\"\",\n",
    "    system_prompt=\"You are a logistics analyst. Always respond with valid JSON.\"\n",
    ")\n",
    "\n",
    "print(f\"JSON Response:\")\n",
    "print(f\"  Success: {json_response['success']}\")\n",
    "print(f\"  Parsed: {json_response.get('parsed')}\")\n",
    "\n",
    "if json_response.get('parse_error'):\n",
    "    print(f\"  Parse Error: {json_response['parse_error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Error Handling and Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with intentionally unavailable client\n",
    "test_client = GrokClient(api_key=\"\")  # Empty API key\n",
    "\n",
    "print(f\"Test client available: {test_client.is_available}\")\n",
    "\n",
    "# Should trigger fallback\n",
    "fallback_response = test_client.complete(\n",
    "    prompt=\"Test prompt for issue detection\",\n",
    "    system_prompt=\"Test system\"\n",
    ")\n",
    "\n",
    "print(f\"\\nFallback Response:\")\n",
    "print(f\"  Success: {fallback_response['success']}\")\n",
    "print(f\"  Model: {fallback_response['model']}\")\n",
    "print(f\"  Error: {fallback_response.get('error')}\")\n",
    "print(f\"  Content: {fallback_response['content'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usage Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check client statistics\n",
    "stats = client.get_stats()\n",
    "\n",
    "print(\"Client Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Logistics-Specific Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test logistics-specific prompt\n",
    "logistics_prompt = \"\"\"\n",
    "Analyze the following fleet situation:\n",
    "\n",
    "Fleet Status:\n",
    "- 5 trucks active\n",
    "- 2 trucks en-route, both reporting slow speeds (15 km/h)\n",
    "- 1 truck idle at warehouse\n",
    "- 2 trucks loading/unloading\n",
    "\n",
    "Traffic:\n",
    "- I-95 Northbound: Heavy traffic, 25 km/h average\n",
    "- Route 9A: Light traffic, 55 km/h average\n",
    "\n",
    "Pending Deliveries:\n",
    "- 3 deliveries due within 2 hours (HIGH priority)\n",
    "- 2 deliveries due within 4 hours (NORMAL priority)\n",
    "\n",
    "Provide analysis in JSON format with: situation_summary, issues (array), recommendations (array)\n",
    "\"\"\"\n",
    "\n",
    "logistics_response = client.complete_json(\n",
    "    prompt=logistics_prompt,\n",
    "    system_prompt=\"You are an expert logistics fleet manager. Analyze situations and provide actionable insights.\"\n",
    ")\n",
    "\n",
    "print(\"Logistics Analysis:\")\n",
    "if logistics_response.get('parsed'):\n",
    "    import json\n",
    "    print(json.dumps(logistics_response['parsed'], indent=2))\n",
    "else:\n",
    "    print(logistics_response['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Singleton Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test singleton access\n",
    "client1 = get_grok_client()\n",
    "client2 = get_grok_client()\n",
    "\n",
    "print(f\"Singleton test: {client1 is client2}\")\n",
    "print(f\"Client available: {client1.is_available}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Integration Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"GROK INTEGRATION TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "tests_passed = 0\n",
    "tests_total = 0\n",
    "\n",
    "# Test 1: Client creation\n",
    "tests_total += 1\n",
    "try:\n",
    "    test_client = GrokClient()\n",
    "    assert test_client is not None\n",
    "    print(\"✓ Test 1: Client creation\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 1: {e}\")\n",
    "\n",
    "# Test 2: Complete method\n",
    "tests_total += 1\n",
    "try:\n",
    "    response = test_client.complete(\"Hello\")\n",
    "    assert 'content' in response\n",
    "    assert 'success' in response\n",
    "    print(\"✓ Test 2: Complete method\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 2: {e}\")\n",
    "\n",
    "# Test 3: JSON complete method\n",
    "tests_total += 1\n",
    "try:\n",
    "    response = test_client.complete_json(\"Return {\\\"test\\\": true}\")\n",
    "    assert 'content' in response\n",
    "    print(\"✓ Test 3: JSON complete method\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 3: {e}\")\n",
    "\n",
    "# Test 4: Fallback handling\n",
    "tests_total += 1\n",
    "try:\n",
    "    fallback_client = GrokClient(api_key=\"\")\n",
    "    response = fallback_client.complete(\"Test\")\n",
    "    assert response['model'] == 'fallback'\n",
    "    print(\"✓ Test 4: Fallback handling\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 4: {e}\")\n",
    "\n",
    "# Test 5: Stats tracking\n",
    "tests_total += 1\n",
    "try:\n",
    "    stats = test_client.get_stats()\n",
    "    assert 'total_requests' in stats\n",
    "    assert 'is_available' in stats\n",
    "    print(\"✓ Test 5: Stats tracking\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 5: {e}\")\n",
    "\n",
    "# Test 6: Singleton\n",
    "tests_total += 1\n",
    "try:\n",
    "    c1 = get_grok_client()\n",
    "    c2 = get_grok_client()\n",
    "    assert c1 is c2\n",
    "    print(\"✓ Test 6: Singleton pattern\")\n",
    "    tests_passed += 1\n",
    "except Exception as e:\n",
    "    print(f\"✗ Test 6: {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tests passed: {tests_passed}/{tests_total}\")\n",
    "if tests_passed == tests_total:\n",
    "    print(\"✓ All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Notes\n",
    "\n",
    "To use Grok with a real API key:\n",
    "\n",
    "1. Copy `.env.template` to `.env`\n",
    "2. Set `XAI_API_KEY=your-api-key`\n",
    "3. Restart the notebook\n",
    "\n",
    "The client will automatically use fallback responses when the API is unavailable.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Proceed to `05_reasoning_prompts.ipynb` for prompt engineering\n",
    "2. Then `06_reasoning_layer.ipynb` for complete reasoning implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
